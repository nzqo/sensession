{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca4e76-2d44-4251-9cb1-c7fdc4232a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9152b8d-7d34-4c0f-950b-199d3b667676",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "First load and inspect the data\n",
    "\n",
    "**NOTE:** I removed the antenna dependency for now, since we are only considering data captures with one antenna. We should probably have multiple-antenna captures as well, though. In the simplest case, the code should still work since we can flatten out the CSI values (instead of $54$ we would have $n \\cdot 54$, $n$ being the anntena number).\n",
    "\n",
    "**NOTE2:** I have not removed the phases, since we are really interested in phases. However, so far, the curves are only used to scale amplitudes, since phases are a bit more complex.. We should not forget that they should be part of the equation though.\n",
    "\n",
    "**Question:** If we use multiple antennas, which provide very important information about the received radiation (e.g. directivity), would we also change the network architectures in some way to target that? In a similar way that RGB values sometimes have separate layers for R, G and B values? We should keep that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d626fc-14e2-4acf-b28e-bea835b27dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters for this notebook\n",
    "curves_file = \"../data/random_dyncurves_30db/curves.parquet\"\n",
    "exp_db_file = \"../data/random_dyncurves_30db/preprocessed.parquet\"\n",
    "\n",
    "curve_df = pl.read_parquet(curves_file)\n",
    "csi_df = pl.read_parquet(exp_db_file)\n",
    "\n",
    "\n",
    "def glimpse(df: pl.DataFrame, num_vals: int = 5):\n",
    "    print(\n",
    "        \"-------------------------------------------------------------\\n\"\n",
    "        + f\"A glimpse of the first {num_vals} entries in the data frame:\"\n",
    "    )\n",
    "    with pl.Config() as cfg:\n",
    "        cfg.set_tbl_cols(-1)\n",
    "        cfg.set_tbl_width_chars(140)\n",
    "        print(df.limit(num_vals))\n",
    "        print()\n",
    "\n",
    "\n",
    "glimpse(curve_df, 2)\n",
    "glimpse(csi_df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e7345-626d-4b6b-9e76-6c69391fad58",
   "metadata": {},
   "source": [
    "# Note on dimensions\n",
    "\n",
    "We now always have $700$ values for every session, some of which will be null. Just to exemplify this, I searched for one by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79f838-3772-416c-8723-afd90f1b09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_datapoint_idx = 88\n",
    "with pl.Config() as cfg:\n",
    "    cfg.set_tbl_cols(-1)\n",
    "    cfg.set_tbl_width_chars(140)\n",
    "    print(csi_df[missing_datapoint_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85ec4c-16cd-49ab-a2a0-d5fbab079064",
   "metadata": {},
   "source": [
    "# Subsampling\n",
    "\n",
    "I rewrote the subsampling to be a bit more configurable and easier to understand. I am not using it per default, but feel free to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db83fa-ab05-48f8-929c-9e4795f2643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(\n",
    "    df: pl.DataFrame,\n",
    "    target_num: int,\n",
    "    num_packets_total: int = 700,\n",
    "    safe_period_ms: int = 500,\n",
    "):\n",
    "    \"\"\"\n",
    "    Subsample each of the 700 packet CSI sequences to a target of target_num\n",
    "    packets. This helps in fighting data loss.\n",
    "    \"\"\"\n",
    "    # Period in which there is at least one value. If this isn't the case,\n",
    "    # subsampling will crash. This is fine because in such a case subsampling\n",
    "    # doesn't make much sense. Missing values are essentially substituted by\n",
    "    # the closest available ones. If that \"closest\" is actually far away, that\n",
    "    # would suck.\n",
    "    safe_period = timedelta(milliseconds=safe_period_ms)\n",
    "\n",
    "    # Ensure we are actually performing \"sub\" sampling\n",
    "    assert target_num < num_packets_total, \"can not supersample!\"\n",
    "\n",
    "    print(\n",
    "        \"Subsampling series to circumvent missing values: \\n\"\n",
    "        + f\"Subsampling ratio: {target_num}/{num_packets_total}\"\n",
    "    )\n",
    "\n",
    "    # NOTE: The dynamic groupby itself does not perform subsampling, it simply\n",
    "    # performs windowed grouping. That means that every \"subsample_timedelta\",\n",
    "    # it will group all values within a \"500ms\" period from then.\n",
    "    # To subsample, we take the very first appearing values in all the windows.\n",
    "    aggs = [\n",
    "        pl.col(\"csi_abs\").first(),\n",
    "        pl.col(\"csi_phase\").first(),\n",
    "        pl.col(\"session_id\").first(),\n",
    "        pl.col(\"receiver_name\").first(),\n",
    "        pl.col(\"num_curve\").first(),\n",
    "        pl.col(\"subcarrier_idxs\").first(),\n",
    "        pl.col(\"antenna_rssi\").first(),\n",
    "    ]\n",
    "\n",
    "    # Drop null values, then perform the subsampling and truncate to the target\n",
    "    # subsampling number\n",
    "    def grouper(group: pl.DataFrame) -> pl.DataFrame:\n",
    "        min_time = group.select(pl.min(\"timestamp\")).item()\n",
    "        max_time = group.select(pl.max(\"timestamp\")).item()\n",
    "        total_time = max_time - min_time\n",
    "        subsample_timedelta = total_time / target_num\n",
    "\n",
    "        return (\n",
    "            group.sort(\"timestamp\")\n",
    "            .group_by_dynamic(\n",
    "                \"timestamp\", every=subsample_timedelta, period=safe_period\n",
    "            )\n",
    "            .agg(*aggs)\n",
    "            .head(target_num)\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        df.drop_nulls()\n",
    "        .group_by(\"session_id\", \"receiver_name\", maintain_order=True)\n",
    "        .map_groups(grouper)\n",
    "    )\n",
    "\n",
    "\n",
    "# Opt-in to subsampling by uncommenting this line.\n",
    "# Feel free to change the target dimension as well, 152 is arbitrary.\n",
    "# csi_df = subsample(csi_df, 152)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b6eee-25f6-4702-954c-47f97467c275",
   "metadata": {},
   "source": [
    "# Numpy Conversion\n",
    "\n",
    "Conversion to numpy is actually straightforward now. This produces a few arrays, namely:\n",
    "\n",
    "- Both the absolute CSI values and the phases\n",
    "- RSSI, a single valued quantity per packet describing signal strength\n",
    "- The groundtruth curve array the CSI is meant to represent (In this case only the absolute value)\n",
    "- Labels corresponding to the receiver and curve\n",
    "\n",
    "**NOTE:** Importantly, this data still contains None values if downsampling wasn't performed. Imputation should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac5bb4-3f5f-4951-a03e-f11c7e20665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_to_numpy(df: pl.DataFrame, column: str) -> np.ndarray:\n",
    "    return np.array(df.get_column(column).to_list())\n",
    "\n",
    "\n",
    "# -- Session regrouping\n",
    "numpy_df = csi_df.group_by(\n",
    "    \"session_id\",\n",
    "    \"receiver_name\",\n",
    "    \"num_curve\",\n",
    "    \"subcarrier_idxs\",\n",
    "    maintain_order=True,\n",
    ").agg(\"csi_abs\", \"csi_phase\", \"antenna_rssi\", \"timestamp\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Now convert to array, first the data ...\n",
    "# NOTE: to_numpy doesnt do nested lists, so instead we take the roundabout way over lists\n",
    "csi_abs = col_to_numpy(numpy_df, \"csi_abs\")\n",
    "csi_phase = col_to_numpy(numpy_df, \"csi_phase\")\n",
    "rssi = col_to_numpy(numpy_df, \"antenna_rssi\")\n",
    "\n",
    "# ... then the labels\n",
    "curve_labels = col_to_numpy(numpy_df, \"num_curve\")\n",
    "receiver_labels = col_to_numpy(numpy_df, \"receiver_name\")\n",
    "labels = np.array(list(zip(receiver_labels, curve_labels)))\n",
    "\n",
    "# ... and the ground truth curves\n",
    "# NOTE: Curves are currently one-dimensional, but that is just due to the experiment.\n",
    "# Technically, we could use different curves for all 54 subcarriers.\n",
    "# Hence, we should treat the curves as being 700x54 dimensional!\n",
    "num_subcs = 54\n",
    "curves = col_to_numpy(curve_df, \"curve\")\n",
    "curves = np.repeat(curves[:, :, np.newaxis], 54, axis=2)\n",
    "curve_groundtruth = curves[curve_labels, :, :]\n",
    "\n",
    "# Note: num_capture is just a time index or the sequence number, if you will\n",
    "print(\n",
    "    \"Dimensions: session x num_capture x csi_subcarrier\\n\"\n",
    "    + f\"CSI absolute values shape                        : {csi_abs.shape}\\n\"\n",
    "    + f\"CSI phase values shape                           : {csi_phase.shape}\\n\"\n",
    "    + f\"Ground truth of curves shape                     : {curve_groundtruth.shape}\\n\"\n",
    "    + f\"Labels shape (receiver name and curve identifier): {labels.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab84dc-4143-4f46-998b-50db272d3a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
